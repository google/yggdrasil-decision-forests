/*
 * Copyright 2022 Google LLC.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto2";

package yggdrasil_decision_forests.metric.proto;

import "yggdrasil_decision_forests/dataset/data_spec.proto";
import "yggdrasil_decision_forests/dataset/weight.proto";
import "yggdrasil_decision_forests/model/abstract_model.proto";
import "yggdrasil_decision_forests/model/prediction.proto";
import "yggdrasil_decision_forests/utils/distribution.proto";

// Configuration of the evaluation of a model. Describes how the evaluation
// should be done.
message EvaluationOptions {
  message Classification {
    // Do compute the ROC metrics (or other metrics using the same type of
    // computation e.g. PR-AUC, P@R).
    optional bool roc_enable = 1 [default = true];
    // Maximum number of points in the ROC curve.
    optional int64 max_roc_samples = 2 [default = 10000];
    // List of recall values (between 0 and 1) for the evaluation of precision
    // at given recall.
    repeated double precision_at_recall = 3;
    // List of precision values (between 0 and 1) for the evaluation of recall
    // at given precision.
    repeated double recall_at_precision = 4;
    // List of volume values (between 0 and 1) for the evaluation of precision
    // at given volume.
    repeated double precision_at_volume = 5;
    // List of false positive rates for the evaluation of recall at given false
    // positive rates.
    repeated double recall_at_false_positive_rate = 6;
    // List of false recall for the evaluation of false positive rate at given
    // recall.
    repeated double false_positive_rate_at_recall = 7;
    // Next ID: 8
  }

  message Regression {
    // Do compute the regression plots (histogram of ground truth, residual and
    // predictions, normality test of residual, conditional plots).
    optional bool enable_regression_plots = 1 [default = true];
  }

  message Ranking {
    // Number of evaluated elements.
    optional int32 ndcg_truncation = 1 [default = 5];
    // Rank cut-off at which Mean Reciprocal Rank is computed.
    optional int32 mrr_truncation = 2 [default = 10];
    // If false (default) and if all the predictions (items) are in the same
    // group (i.e. there is only one group), raises an error.
    optional bool allow_only_one_group = 3 [default = false];
  }

  message Uplift {}

  // Task of the model.
  optional model.proto.Task task = 1 [default = CLASSIFICATION];
  // Evaluation configuration depending on the type of problem.
  oneof task_options {
    Classification classification = 2;
    Regression regression = 3;
    Ranking ranking = 7;
    Uplift uplift = 8;
  }
  // Percentage of sampled predictions. If no predictions need to be sampled
  // (i.e. no part of the configuration needs it), this parameter is ignored and
  // no prediction is sampled.
  optional float prediction_sampling = 4 [default = 1];

  // Number of bootstrapping samples used to evaluate metric confidence
  // intervals and statistical test (i.e. all the metric ending with "[B]"). If
  // <=0, bootstrapping estimation is disabled. Note: Bootstrapping is done on
  // the sampled predictions (controlled by "prediction_sampling" parameter).
  // Note: Bootstrapping is an expensive computation. Therefore, for quick
  // experimentation with modeling, bootstrapping can be temporally reduced or
  // disabled.
  optional int64 bootstrapping_samples = 5 [default = 2000];

  // Weights of the examples. This field does not have to match the
  // "weight_definition" in the model training. For example, the weighting can
  // be enabled for evaluation and disabled for training. Such case is rare
  // however.
  optional dataset.proto.WeightDefinition weights = 6;

  // Next ID: 8
}

// Evaluation results of a model.
//
// This proto is generated by the "EvaluateLearner" or "model->Evaluate()"
// functions.
//
// For manual evaluation, this proto is best generated using the
// "InitializeEvaluation", "AddPrediction" and "FinalizeEvaluation" functions in
// "metric.h".
//
// This proto can be converted into human readable text with "AppendTextReport"
// or into a html+plot with "SaveEvaluationInDirectory". The html version
// contains more information that the raw text.
//
// Individual metrics can be extracted using the utility methods defined in
// "metrics.h" e.g. "Accuracy()", "LogLoss()", "RMSE()".
message EvaluationResults {
  message Classification {
    // Confusion between the label and the predictions. Note that confusion
    // tables are stored column major (which, admittedly, is confusing).
    optional utils.proto.IntegersConfusionMatrixDouble confusion = 1;
    // One-vs-other Receiver operating characteristic curve. Indexed by the
    // categorical label value.
    repeated Roc rocs = 2;
    // Sum of the log loss.
    optional double sum_log_loss = 3 [default = 0];
    // Unused entry.
    reserved 4;
    // Accuracy of the model. If both "accuracy" and "confusion" is specified,
    // they represent the same value.
    optional double accuracy = 5;
    // Next ID: 6
  }

  message Regression {
    // Sum for the squared error. For regression only.
    optional double sum_square_error = 1 [default = 0];
    // Sum of the labels.
    optional double sum_label = 2 [default = 0];
    // Sum of the square of the labels.
    optional double sum_square_label = 3 [default = 0];
    // Lower and upper bounds of the RMSE computed using non-parametric
    // bootstrapping.
    optional double bootstrap_rmse_lower_bounds_95p = 4;
    optional double bootstrap_rmse_upper_bounds_95p = 5;
    // Sum of absolute value of the error.
    optional double sum_abs_error = 6 [default = 0];
    // Next ID: 7
  }

  message Ranking {
    optional MetricEstimate ndcg = 5;
    optional int32 ndcg_truncation = 2;
    optional int64 num_groups = 3 [default = 0];
    optional int64 min_num_items_in_group = 10 [default = 0];
    optional int64 max_num_items_in_group = 11 [default = 0];
    optional double mean_num_items_in_group = 12 [default = 0];
    optional double default_ndcg = 4 [default = 0];

    optional MetricEstimate mrr = 8;
    optional int32 mrr_truncation = 9;

    reserved 6, 7;

    // Fraction of examples were the highest predicted example is also the
    // example with the highest relevance value.
    optional MetricEstimate precision_at_1 = 13;

    // Next ID: 14
    reserved 1;
  }

  message Uplift {
    // Note: In the case of multi-treatments, the "auuc" and "qini" are the
    // example weights average of the per-treatment AUUC and Qini.
    //
    // We use the implementation described in Guelman ("Optimal personalized
    // treatment learning models with insurance applications") or in Betlei
    // ("Treatment targeting by AUUC maximization with generalization
    // guarantees") work.
    optional double auuc = 1;
    optional double qini = 2;

    // Number of possible treatments. The treatment values (i.e. the value of
    // the categorical column specifying the treatment) are in [1,
    // num_treatments+1) with value "1" reserved for the control treatment.
    //
    // For example, in case of single-treatment vs control, "num_treatments=2"
    // and the treatment value will be 1 (control) or 2 (treatment).
    optional int32 num_treatments = 3;
    // The Conditional Average Treatment Effect Calibration metrics
    // (cate_calbration) computes the l2 expected calibration error of a binary
    // treatment uplift model. Miscalibration is a phenomenon that magnitute
    // of a treatment effect is overestimated due to overfitting CATE
    // training data. Here we use the expected "l2 norm of difference between
    // 1) predicted CATE, and 2) unbiased estimation of observed CATE" over all
    // uplift values.
    //
    // The metrics value is greater than 0, with lower values being more
    // desirable, i.e. "more calibrated". This metric is defined in
    // equation (2.4) of paper "Calibration Error for Heterogeneous Treatment
    // Effects", by Xu et al. (https://arxiv.org/pdf/2203.13364.pdf)
    optional double cate_calibration = 4;
  }

  // Number of predictions (weighted by example weight).
  optional double count_predictions = 1 [default = 0];
  // Number of predictions (without weights).
  optional int64 count_predictions_no_weight = 2 [default = 0];
  // Samples predictions. Only sampled if necessary (e.g. if ROC is computed).
  repeated model.proto.Prediction sampled_predictions = 3;
  // Number of sampled predictions (weighted by example weight).
  optional double count_sampled_predictions = 4 [default = 0];
  // Task of the model.
  optional model.proto.Task task = 5 [default = CLASSIFICATION];
  // Evaluation results depending on the type of problem.
  oneof type {
    Classification classification = 6;
    Regression regression = 7;
    Ranking ranking = 12;
    Uplift uplift = 14;
  }
  // The dataspec of the label column. This field can contain information such
  // as: The possible label values, the distribution of the label values, the
  // string representation of the label value, etc.
  optional dataset.proto.Column label_column = 8;

  // Training time of the model. In case of cross-validation evaluation results,
  // "training_duration_in_seconds" is the average training time of a single
  // model.
  optional float training_duration_in_seconds = 9;

  // Value of the loss function used to optimize the model.
  //
  // Not all machine learning algorithms are optimizing a loss function, and
  // different loss functions can be compatible for a given task.
  optional float loss_value = 10;
  optional string loss_name = 11;

  // Number of folds used for the evaluation.
  // The number of folds is 1 for train-and-test, and equals to the
  // cross-validation number of folds in case of cross-validation.
  optional int32 num_folds = 13;

  // User can use this field to store value for any customized metrics.
  map<string, double> user_metrics = 15;
  // Next ID: 16
}

// Reference a metric."MetricAccessor" is used as a parameter of the function
// "GetMetric" to extract metric values from evaluation results proto.
//
// Example:
// a = EvaluationResults { classification { accuracy:0.7 auc:0.8 ap:0.9 } }
// b = MetricAccessor { classification {}}
// GetMetric(a,b) -> 0.7
message MetricAccessor {
  oneof Task {
    Classification classification = 1;
    Regression regression = 2;
    Loss loss = 3;
    Ranking ranking = 4;
    Uplift uplift = 5;
    UserMetric user_metric = 6;
  }

  message Classification {
    oneof Type {
      Accuracy accuracy = 1;
      LogLoss logloss = 2;
      OneVsOther one_vs_other = 3;
    }
    message Accuracy {}
    message LogLoss {}
    message OneVsOther {
      optional string positive_class = 1;
      oneof Type {
        Auc auc = 2;
        PrAuc pr_auc = 3;
        Ap ap = 4;
        PrecisionAtRecall precision_at_recall = 5;
        RecallAtPrecision recall_at_precision = 6;
        PrecisionAtVolume precision_at_volume = 7;
        RecallAtFalsePositiveRate recall_at_false_positive_rate = 8;
        FalsePositiveRateAtRecall false_positive_rate_at_recall = 9;
      }
      message Auc {}
      message PrAuc {}
      message Ap {}
      message PrecisionAtRecall {
        optional float recall = 1;
      }
      message RecallAtPrecision {
        optional float precision = 1;
      }
      message PrecisionAtVolume {
        optional float volume = 1;
      }
      message RecallAtFalsePositiveRate {
        optional float false_positive_rate = 1;
      }
      message FalsePositiveRateAtRecall {
        optional float recall = 1;
      }
    }
  }

  message Regression {
    oneof Type {
      Rmse rmse = 1;
      Mae mae = 2;
    }
    message Rmse {}
    message Mae {}
  }

  message Loss {}

  message Ranking {
    oneof Type {
      NDCG ndcg = 1;
      MRR mrr = 2;
    }
    message NDCG {}
    message MRR {}
  }

  message Uplift {
    oneof type {
      Qini qini = 1;
      CateCalibration cate_calibration = 2;
    }
    message Qini {}
    message CateCalibration {}
  }

  message UserMetric {
    optional string metrics_name = 1;
  }
}

// A receiver operating characteristic curve.
message Roc {
  message Point {
    optional float threshold = 1;
    // True/False Positive/Negative.
    optional double tp = 2;
    optional double fp = 3;
    optional double tn = 4;
    optional double fn = 5;
  }
  // Points sorted with decreasing recall (i.e. increasing threshold).
  repeated Point curve = 1;
  // Sum of the tp+fp+tn+fn of one element (this is the same for all elements).
  // "sum" is equal to "count_predictions" if the ROC is computed without
  // sampling (i.e. roc_prediction_sampling==1).
  optional double count_predictions = 2;
  // Area under the curve.
  optional double auc = 3;
  // Precision/Recall AUC.
  optional double pr_auc = 4;
  // Average Precision.
  optional double ap = 10;

  // Value of a metric X (e.g. recall) for a given other metric Y value (e.g.
  // FPR).
  message XAtYMetric {
    optional double y_metric_constraint = 1;
    optional double x_metric_value = 2;
    optional float threshold = 3;
  }
  // Metric X evaluated under constraint of a given metric Y value.
  // These three fields have the same number of element as the fields of the
  // same name in "EvaluationOptions::Classification".
  repeated XAtYMetric precision_at_recall = 5;
  repeated XAtYMetric recall_at_precision = 6;
  repeated XAtYMetric precision_at_volume = 7;
  repeated XAtYMetric recall_at_false_positive_rate = 8;
  repeated XAtYMetric false_positive_rate_at_recall = 9;

  // Lower and upper bounds of all metrics computed using non-parametric
  // percentile bootstrapping. Only available if bootstrapping is enabled i.e.
  // num_bootstrapping_samples>=1.
  optional Roc bootstrap_lower_bounds_95p = 11;
  optional Roc bootstrap_upper_bounds_95p = 12;

  // Next ID: 13
}

// Estimated measure of a metric.
message MetricEstimate {
  // Expected value.
  optional double value = 1;

  // Upper and lower 95% bound estimated using bootstrapping.
  optional Bounds bootstrap_based_95p = 2;
}

message Bounds {
  optional double lower = 1;
  optional double upper = 2;
}
