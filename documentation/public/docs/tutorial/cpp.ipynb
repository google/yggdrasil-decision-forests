{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In C++\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/yggdrasil-decision-forests/blob/main/documentation/public/docs/tutorial/cpp.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ydf -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Serving in C++\n",
    "YDF models can be served directly in C++ through the C++ library. Since the Python API and the C++ API share the same serving code, models are fully cross-compatible.\n",
    "\n",
    "**Benefits of serving with C++**\n",
    "-   Optimized inference speed: The C++ API offers full control over the serving code, which can be used to squeeze every nanosecond of performance out of YDF.\n",
    "-   Optimized binary size: Since the C++ serving code does not depend on the training code, only a small fraction of YDF must be linked.\n",
    "\n",
    "**When not to use the C++ API**\n",
    "-   The C++ API is not as easy to use as the Python API.\n",
    "-   Preprocessing, if any, must be regenerated in C++.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a small model\n",
    "\n",
    "The next cell creates a very small YDF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 150 examples\n",
      "Model trained in 0:00:00.003721\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       ".tab_block .header {\n",
       "    flex-direction: row;\n",
       "    display: flex;\n",
       "}\n",
       "\n",
       ".tab_block .header .tab {\n",
       "    cursor: pointer;\n",
       "    background-color: #F6F5F5;\n",
       "    text-decoration: none;\n",
       "    text-align: center;\n",
       "    padding: 4px 12px;\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".tab_block .header .tab.selected {\n",
       "    border-bottom: 2px solid #2F80ED;\n",
       "}\n",
       "\n",
       ".tab_block .header .tab:hover {\n",
       "    text-decoration: none;\n",
       "    background-color: #DCDCDC;\n",
       "}\n",
       "\n",
       ".tab_block .body .tab_content {\n",
       "    display: none;\n",
       "    padding: 5px;\n",
       "}\n",
       "\n",
       ".tab_block .body .tab_content.selected {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".ydf_pre {\n",
       "    font-size: medium;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       ".variable_importance {\n",
       "}\n",
       "\n",
       ".variable_importance select {\n",
       "}\n",
       "\n",
       ".variable_importance .content {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".variable_importance .content.selected {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".ydf_tuning_table {\n",
       "  border-collapse: collapse;\n",
       "  border: 1px solid lightgray;\n",
       "}\n",
       "\n",
       ".ydf_tuning_table th {\n",
       "  background-color: #ededed;\n",
       "  font-weight: bold;\n",
       "  text-align: left;\n",
       "  padding: 3px 4px;\n",
       "  border: 1px solid lightgray;\n",
       "}\n",
       "\n",
       ".ydf_tuning_table td {\n",
       "  text-align: right;\n",
       "  padding: 3px 4px;\n",
       "  border: 1px solid lightgray;\n",
       "}\n",
       "\n",
       ".ydf_tuning_table .best {\n",
       "  background-color: khaki;\n",
       "}\n",
       "\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "\n",
       "function ydfShowTab(block_id, item) {\n",
       "    const block = document.getElementById(block_id);\n",
       "    \n",
       "    \n",
       "    console.log(\"HIDE first of:\",block.getElementsByClassName(\"tab selected\"));\n",
       "    console.log(\"HIDE first of:\",block.getElementsByClassName(\"tab_content selected\"));\n",
       "    \n",
       "    block.getElementsByClassName(\"tab selected\")[0].classList.remove(\"selected\");\n",
       "    block.getElementsByClassName(\"tab_content selected\")[0].classList.remove(\"selected\");\n",
       "    document.getElementById(block_id + \"_\" + item).classList.add(\"selected\");\n",
       "    document.getElementById(block_id + \"_body_\" + item).classList.add(\"selected\");\n",
       "}\n",
       "  \n",
       "\n",
       "function ydfShowVariableImportance(block_id) {\n",
       "    const block = document.getElementById(block_id);\n",
       "    const item = block.getElementsByTagName(\"select\")[0].value;\n",
       "    block.getElementsByClassName(\"content selected\")[0].classList.remove(\"selected\");\n",
       "    document.getElementById(block_id + \"_body_\" + item).classList.add(\"selected\");\n",
       "}\n",
       "\n",
       "</script>\n",
       "  <div class=\"tab_block\" id=\"ae71-191e-067e-631f\"><div class=\"header\"><a id=\"ae71-191e-067e-631f_model\" class=\"tab selected\" onclick=\"ydfShowTab('ae71-191e-067e-631f', 'model')\">Model</a><a id=\"ae71-191e-067e-631f_dataspec\" class=\"tab\" onclick=\"ydfShowTab('ae71-191e-067e-631f', 'dataspec')\">Dataspec</a><a id=\"ae71-191e-067e-631f_training\" class=\"tab\" onclick=\"ydfShowTab('ae71-191e-067e-631f', 'training')\">Training</a><a id=\"ae71-191e-067e-631f_variable_importance\" class=\"tab\" onclick=\"ydfShowTab('ae71-191e-067e-631f', 'variable_importance')\">Variable importances</a><a id=\"ae71-191e-067e-631f_structure\" class=\"tab\" onclick=\"ydfShowTab('ae71-191e-067e-631f', 'structure')\">Structure</a></div><div class=\"body\"><div id=\"ae71-191e-067e-631f_body_model\" class=\"tab_content selected\"><b>Name</b> : RANDOM_FOREST<br><b>Task</b> : CLASSIFICATION<br><b>Label</b> : class<br><b>Features (4)</b> : Sepal.Length Sepal.Width Petal.Length Petal.Width<br><b>Weights</b> : None<br><b>Trained with tuner</b> : No<br><b>Model size</b> : 29 kB<br></div><div id=\"ae71-191e-067e-631f_body_dataspec\" class=\"tab_content\"><pre class=\"ydf_pre\">Number of records: 150\n",
       "Number of columns: 5\n",
       "\n",
       "Number of columns by type:\n",
       "\tNUMERICAL: 4 (80%)\n",
       "\tCATEGORICAL: 1 (20%)\n",
       "\n",
       "Columns:\n",
       "\n",
       "NUMERICAL: 4 (80%)\n",
       "\t1: &quot;Sepal.Length&quot; NUMERICAL mean:5.84333 min:4.3 max:7.9 sd:0.825301\n",
       "\t2: &quot;Sepal.Width&quot; NUMERICAL mean:3.05733 min:2 max:4.4 sd:0.434411\n",
       "\t3: &quot;Petal.Length&quot; NUMERICAL mean:3.758 min:1 max:6.9 sd:1.7594\n",
       "\t4: &quot;Petal.Width&quot; NUMERICAL mean:1.19933 min:0.1 max:2.5 sd:0.759693\n",
       "\n",
       "CATEGORICAL: 1 (20%)\n",
       "\t0: &quot;class&quot; CATEGORICAL has-dict vocab-size:4 zero-ood-items most-frequent:&quot;setosa&quot; 50 (33.3333%)\n",
       "\n",
       "Terminology:\n",
       "\tnas: Number of non-available (i.e. missing) values.\n",
       "\tood: Out of dictionary.\n",
       "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
       "\ttokenized: The attribute value is obtained through tokenization.\n",
       "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
       "\tvocab-size: Number of unique values.\n",
       "</pre></div><div id=\"ae71-191e-067e-631f_body_training\" class=\"tab_content\"><p>The following evaluation is computed on the validation or out-of-bag dataset.</p><pre class=\"ydf_pre\">Number of predictions (without weights): 149\n",
       "Number of predictions (with weights): 149\n",
       "Task: CLASSIFICATION\n",
       "Label: class\n",
       "\n",
       "Accuracy: 0.919463  CI95[W][0.872779 0.952873]\n",
       "LogLoss: : 0.798053\n",
       "ErrorRate: : 0.0805369\n",
       "\n",
       "Default Accuracy: : 0.33557\n",
       "Default LogLoss: : 1.09857\n",
       "Default ErrorRate: : 0.66443\n",
       "\n",
       "Confusion Table:\n",
       "truth\\prediction\n",
       "            setosa  versicolor  virginica\n",
       "    setosa      50           0          0\n",
       "versicolor       0          47          3\n",
       " virginica       0           9         40\n",
       "Total: 149\n",
       "\n",
       "</pre><div style='display: grid; gap: 0px; grid-auto-columns: min-content;'><div style='grid-row:1 / span 1; grid-column:1 / span 1;'><script src='https://www.gstatic.com/external_hosted/plotly/plotly.min.js'></script>\n",
       "<div id=\"chart_ae71_191e_067e_631fself_eval\" style=\"display: inline-block;\" ></div>\n",
       "<script>\n",
       "  Plotly.newPlot(\n",
       "    'chart_ae71_191e_067e_631fself_eval',\n",
       "    [{\n",
       "x: [1,10],\n",
       "y: [0.960784,0.919463],\n",
       "type: 'scatter',\n",
       "mode: 'lines',\n",
       "line: {\n",
       "  dash: 'solid',\n",
       "  width: 1\n",
       "},\n",
       "},\n",
       "],\n",
       "    {\n",
       "      width: 600,\n",
       "      height: 400,\n",
       "      title: '',\n",
       "      showlegend: true,\n",
       "      xaxis: {\n",
       "        ticks: 'outside',\n",
       "        showgrid: true,\n",
       "        zeroline: false,\n",
       "        showline: true,\n",
       "        title: 'num trees',\n",
       "        },\n",
       "      font: {\n",
       "        size: 10,\n",
       "        },\n",
       "      yaxis: {\n",
       "        ticks: 'outside',\n",
       "        showgrid: true,\n",
       "        zeroline: false,\n",
       "        showline: true,\n",
       "        title: 'accuracy',\n",
       "        },\n",
       "      margin: {\n",
       "        l: 50,\n",
       "        r: 50,\n",
       "        b: 50,\n",
       "        t: 50,\n",
       "      },\n",
       "    },\n",
       "    {\n",
       "      modeBarButtonsToRemove: ['sendDataToCloud'],\n",
       "      displaylogo: false,displayModeBar: false,\n",
       "    }\n",
       "  );\n",
       "</script>\n",
       "</div></div></div><div id=\"ae71-191e-067e-631f_body_variable_importance\" class=\"tab_content\"><p><a target=\"_blank\" href=\"https://ydf.readthedocs.io/cli_user_manual#variable-importances\">Variable importances</a> measure the importance of an input feature for a model.</p><div id=\"ae71-191e-067e-631f_vi\" class=\"variable_importance\"><select onchange=\"ydfShowVariableImportance('ae71-191e-067e-631f_vi')\"><option value=\"INV_MEAN_MIN_DEPTH\">INV_MEAN_MIN_DEPTH</option><option value=\"NUM_AS_ROOT\">NUM_AS_ROOT</option><option value=\"NUM_NODES\">NUM_NODES</option><option value=\"SUM_SCORE\">SUM_SCORE</option></select><div id=\"ae71-191e-067e-631f_vi_body_INV_MEAN_MIN_DEPTH\" class=\"content selected\"><pre class=\"ydf_pre\">    1. &quot;Petal.Length&quot;  0.595238 ################\n",
       "    2.  &quot;Petal.Width&quot;  0.578035 ###############\n",
       "    3.  &quot;Sepal.Width&quot;  0.280786 \n",
       "    4. &quot;Sepal.Length&quot;  0.279107 \n",
       "</pre></div><div id=\"ae71-191e-067e-631f_vi_body_NUM_AS_ROOT\" class=\"content\"><pre class=\"ydf_pre\">    1. &quot;Petal.Length&quot;  5.000000 \n",
       "    2.  &quot;Petal.Width&quot;  5.000000 \n",
       "</pre></div><div id=\"ae71-191e-067e-631f_vi_body_NUM_NODES\" class=\"content\"><pre class=\"ydf_pre\">    1. &quot;Petal.Length&quot; 18.000000 ################\n",
       "    2.  &quot;Petal.Width&quot; 15.000000 ############\n",
       "    3.  &quot;Sepal.Width&quot;  5.000000 ##\n",
       "    4. &quot;Sepal.Length&quot;  3.000000 \n",
       "</pre></div><div id=\"ae71-191e-067e-631f_vi_body_SUM_SCORE\" class=\"content\"><pre class=\"ydf_pre\">    1. &quot;Petal.Length&quot; 870.339292 ################\n",
       "    2.  &quot;Petal.Width&quot; 676.225185 ############\n",
       "    3.  &quot;Sepal.Width&quot; 12.636705 \n",
       "    4. &quot;Sepal.Length&quot; 12.459391 \n",
       "</pre></div></div><p>Those variable importances are computed during training. More, and possibly more informative, variable importances are available when analyzing a model on a test dataset.</p></div><div id=\"ae71-191e-067e-631f_body_structure\" class=\"tab_content\"><b>Num trees</b> : 10<br><p>Only printing the first tree.</p><pre class=\"ydf_pre\">Tree #0:\n",
       "    &quot;Petal.Length&quot;&gt;=2.6 [s:0.673012 n:150 np:90 miss:1] ; val:&quot;setosa&quot; prob:[0.4, 0.266667, 0.333333]\n",
       "        ├─(pos)─ &quot;Petal.Width&quot;&gt;=1.75 [s:0.512546 n:90 np:45 miss:0] ; val:&quot;virginica&quot; prob:[0, 0.444444, 0.555556]\n",
       "        |        ├─(pos)─ val:&quot;virginica&quot; prob:[0, 0, 1]\n",
       "        |        └─(neg)─ &quot;Petal.Length&quot;&gt;=4.95 [s:0.139839 n:45 np:7 miss:0] ; val:&quot;versicolor&quot; prob:[0, 0.888889, 0.111111]\n",
       "        |                 ├─(pos)─ val:&quot;virginica&quot; prob:[0, 0.428571, 0.571429]\n",
       "        |                 └─(neg)─ &quot;Sepal.Length&quot;&gt;=5.55 [s:0.0505512 n:38 np:32 miss:1] ; val:&quot;versicolor&quot; prob:[0, 0.973684, 0.0263158]\n",
       "        |                          ├─(pos)─ val:&quot;versicolor&quot; prob:[0, 1, 0]\n",
       "        |                          └─(neg)─ val:&quot;versicolor&quot; prob:[0, 0.833333, 0.166667]\n",
       "        └─(neg)─ val:&quot;setosa&quot; prob:[1, 0, 0]\n",
       "</pre></div></div></div>"
      ],
      "text/plain": [
       "<ydf.utils.html.HtmlNotebookDisplay at 0x7fbeba2698d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import ydf  # Yggdrasil Decision Forests\n",
    "import pandas as pd  # We use Pandas to load small datasets\n",
    "\n",
    "# Download a classification dataset and load it as a Pandas DataFrame.\n",
    "ds_path = \"https://raw.githubusercontent.com/google/yggdrasil-decision-forests/main/yggdrasil_decision_forests/test_data/dataset\"\n",
    "train_ds = pd.read_csv(f\"{ds_path}/iris.csv\")\n",
    "label = \"class\"\n",
    "\n",
    "model = ydf.RandomForestLearner(label=label, num_trees=10).train(train_ds)\n",
    "\n",
    "model.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the C++ code\n",
    "\n",
    "With `model.to_cpp()`, YDF creates a working C++ file that can be imported in an existing C++ project. The namespace of the C++ code is controlled with the `key=` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Automatically generated code running an Yggdrasil Decision Forests model in\n",
      "// C++. This code was generated with \"model.to_cpp()\".\n",
      "//\n",
      "// Date of generation: 2023-11-01 13:06:59.075973\n",
      "// YDF Version: 0.0.3\n",
      "//\n",
      "// How to use this code:\n",
      "//\n",
      "// 1. Copy this code in a new .h file.\n",
      "// 2. If you use Bazel/Blaze, use the following dependencies:\n",
      "//      //third_party/absl/status:statusor\n",
      "//      //third_party/absl/strings\n",
      "//      //external/ydf_cc/yggdrasil_decision_forests/api:serving\n",
      "// 3. In your existing code, include the .h file and do:\n",
      "//   // Load the model (to do only once).\n",
      "//   namespace ydf = yggdrasil_decision_forests;\n",
      "//   const auto model = ydf::exported_model_123::Load(<path to model>);\n",
      "//   // Run the model\n",
      "//   predictions = model.Predict();\n",
      "// 4. By default, the \"Predict\" function takes no inputs and creates fake\n",
      "//   examples. In practice, you want to add your input data as arguments to\n",
      "//   \"Predict\" and call \"examples->Set...\" functions accordingly.\n",
      "// 4. (Bonus)\n",
      "//   Allocate one \"examples\" and \"predictions\" per thread and reuse them to\n",
      "//   speed-up the inference.\n",
      "//\n",
      "#ifndef YGGDRASIL_DECISION_FORESTS_GENERATED_MODEL_ydf_tutorial\n",
      "#define YGGDRASIL_DECISION_FORESTS_GENERATED_MODEL_ydf_tutorial\n",
      "\n",
      "#include <memory>\n",
      "#include <vector>\n",
      "\n",
      "#include \"third_party/absl/status/statusor.h\"\n",
      "#include \"third_party/absl/strings/string_view.h\"\n",
      "#include \"external/ydf_cc/yggdrasil_decision_forests/api/serving.h\"\n",
      "\n",
      "namespace yggdrasil_decision_forests {\n",
      "namespace exported_model_ydf_tutorial {\n",
      "\n",
      "struct ServingModel {\n",
      "  std::vector<float> Predict() const;\n",
      "\n",
      "  // Compiled model.\n",
      "  std::unique_ptr<serving_api::FastEngine> engine;\n",
      "\n",
      "  // Index of the input features of the model.\n",
      "  //\n",
      "  // Non-owning pointer. The data is owned by the engine.\n",
      "  const serving_api::FeaturesDefinition* features;\n",
      "\n",
      "  // Number of output predictions for each example.\n",
      "  // Equal to 1 for regression, ranking and binary classification with compact\n",
      "  // format. Equal to the number of classes for classification.\n",
      "  int NumPredictionDimension() const {\n",
      "    return engine->NumPredictionDimension();\n",
      "  }\n",
      "\n",
      "  // Indexes of the input features.\n",
      "  serving_api::NumericalFeatureId feature_Sepal_Length;\n",
      "  serving_api::NumericalFeatureId feature_Sepal_Width;\n",
      "  serving_api::NumericalFeatureId feature_Petal_Length;\n",
      "  serving_api::NumericalFeatureId feature_Petal_Width;\n",
      "};\n",
      "\n",
      "// TODO: Pass input feature values to \"Predict\".\n",
      "inline std::vector<float> ServingModel::Predict() const {\n",
      "  // Allocate memory for 2 examples. Alternatively, for speed-sensitive code,\n",
      "  // an \"examples\" object can be allocated for each thread and reused. It is\n",
      "  // okay to allocate more examples than needed.\n",
      "  const int num_examples = 2;\n",
      "  auto examples = engine->AllocateExamples(num_examples);\n",
      "\n",
      "  // Set all the values to be missing. The values may then be overridden by the\n",
      "  // \"Set*\" methods. If all the values are set with \"Set*\" methods,\n",
      "  // \"FillMissing\" can be skipped.\n",
      "  examples->FillMissing(*features);\n",
      "\n",
      "  // Example #0\n",
      "  examples->SetNumerical(/*example_idx=*/0, feature_Sepal_Length, 1.f, *features);\n",
      "  examples->SetNumerical(/*example_idx=*/0, feature_Sepal_Width, 1.f, *features);\n",
      "  examples->SetNumerical(/*example_idx=*/0, feature_Petal_Length, 1.f, *features);\n",
      "  examples->SetNumerical(/*example_idx=*/0, feature_Petal_Width, 1.f, *features);\n",
      "\n",
      "  // Example #1\n",
      "  examples->SetNumerical(/*example_idx=*/1, feature_Sepal_Length, 2.f, *features);\n",
      "  examples->SetNumerical(/*example_idx=*/1, feature_Sepal_Width, 2.f, *features);\n",
      "  examples->SetNumerical(/*example_idx=*/1, feature_Petal_Length, 2.f, *features);\n",
      "  examples->SetNumerical(/*example_idx=*/1, feature_Petal_Width, 2.f, *features);\n",
      "\n",
      "  // Run the model on the two examples.\n",
      "  //\n",
      "  // For speed-sensitive code, reuse the same predictions.\n",
      "  std::vector<float> predictions;\n",
      "  engine->Predict(*examples, num_examples, &predictions);\n",
      "  return predictions;\n",
      "}\n",
      "\n",
      "inline absl::StatusOr<ServingModel> Load(absl::string_view path) {\n",
      "  ServingModel m;\n",
      "\n",
      "  // Load the model\n",
      "  ASSIGN_OR_RETURN(auto model, serving_api::LoadModel(path));\n",
      "\n",
      "  // Compile the model into an inference engine.\n",
      "  ASSIGN_OR_RETURN(m.engine, model->BuildFastEngine());\n",
      "\n",
      "  // Index the input features of the model.\n",
      "  m.features = &m.engine->features();\n",
      "\n",
      "  // Index the input features.\n",
      "  ASSIGN_OR_RETURN(m.feature_Sepal_Length, m.features->GetNumericalFeatureId(\"Sepal.Length\"));\n",
      "  ASSIGN_OR_RETURN(m.feature_Sepal_Width, m.features->GetNumericalFeatureId(\"Sepal.Width\"));\n",
      "  ASSIGN_OR_RETURN(m.feature_Petal_Length, m.features->GetNumericalFeatureId(\"Petal.Length\"));\n",
      "  ASSIGN_OR_RETURN(m.feature_Petal_Width, m.features->GetNumericalFeatureId(\"Petal.Width\"));\n",
      "\n",
      "  return m;\n",
      "}\n",
      "\n",
      "}  // namespace exported_model_ydf_tutorial\n",
      "}  // namespace yggdrasil_decision_forests\n",
      "\n",
      "#endif  // YGGDRASIL_DECISION_FORESTS_GENERATED_MODEL_ydf_tutorial\n"
     ]
    }
   ],
   "source": [
    "# Save the model code to model.h and display it\n",
    "with open(\"ydf_tutorial_model.h\", \"w\") as f:\n",
    "  f.write(model.to_cpp(key=\"ydf_tutorial\"))\n",
    "\n",
    "!cat ydf_tutorial_model.h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the C++ code.\n",
    "\n",
    "To use the C++ code in a project, follow these steps.\n",
    "\n",
    "1.  If you use Bazel/Blaze, create a rule with the dependencies:\n",
    "```\n",
    "      //third_party/absl/status:statusor,\n",
    "      //third_party/absl/strings,\n",
    "      //third_party/yggdrasil_decision_forests/api:serving,\n",
    "```\n",
    "1.  In your C++ code, include the .h file and call the model with:\n",
    "```\n",
    "    // Load the model (to do only once).\n",
    "    namespace ydf = yggdrasil_decision_forests;\n",
    "    const auto model = ydf::exported_model_ydf_tutorial::Load(<path to model>);\n",
    "    // Run the model\n",
    "    predictions = model.Predict();\n",
    "```\n",
    "1.  The generated \"Predict\" function takes no inputs. Instead, it fills the\n",
    "    input features with placeholder values. Therefore, you will want to add\n",
    "    your input as arguments to the \"Predict\" function, and use it to populate\n",
    "    the \"examples->Set...\" section accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further improvements\n",
    "\n",
    "You can further optimize the inference speed by pre-allocating and reusing the examples and predictions for each thread running the model. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
